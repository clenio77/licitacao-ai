# ğŸ›ï¸ Sistema Completo de LicitaÃ§Ãµes dos Correios com IA

## ğŸ“‹ VisÃ£o Geral

Sistema completo e avanÃ§ado para gestÃ£o de licitaÃ§Ãµes dos Correios, integrando:

1. **ğŸ“Š AnÃ¡lise de LicitaÃ§Ãµes Existentes** - Monitoramento e anÃ¡lise de licitaÃ§Ãµes em andamento
2. **ğŸ“ GeraÃ§Ã£o Automatizada de Editais** - CriaÃ§Ã£o inteligente de editais usando IA
3. **ğŸ§  Base de Conhecimento Inteligente** - Web scraping de licitaÃ§Ãµes bem-sucedidas para aprendizado contÃ­nuo

## ğŸš€ Funcionalidades Principais

### 1. AnÃ¡lise de LicitaÃ§Ãµes (Funcionalidade Original)
- Busca automÃ¡tica de licitaÃ§Ãµes dos Correios
- AnÃ¡lise com IA usando OpenAI GPT
- Interface web para visualizaÃ§Ã£o
- Armazenamento em banco SQLite

### 2. GeraÃ§Ã£o de Editais com IA (NOVO)
- **Agentes Especializados CrewAI**:
  - ğŸ‘¨â€ğŸ’¼ Coletor de Requisitos
  - âš–ï¸ Analisador JurÃ­dico  
  - ğŸ”§ Analisador TÃ©cnico
  - ğŸ’° Analisador Financeiro
  - âš ï¸ Especialista em Riscos
  - ğŸ“ Gerador de Edital
  - ğŸ”§ Revisor e Otimizador
  - ğŸ¯ Coordenador do Processo
  - ğŸ§  Especialista em Base de Conhecimento

- **Processo Inteligente**:
  1. Coleta e validaÃ§Ã£o de requisitos
  2. AnÃ¡lises especializadas paralelas
  3. CÃ¡lculo de risco consolidado
  4. GeraÃ§Ã£o do edital baseada em templates
  5. OtimizaÃ§Ã£o com boas prÃ¡ticas
  6. CoordenaÃ§Ã£o final e relatÃ³rio

### 3. Base de Conhecimento com Web Scraping (NOVO)
- **Coleta Automatizada**:
  - Portal da TransparÃªncia
  - ComprasNet (simulado)
  - Dados pÃºblicos de licitaÃ§Ãµes

- **AnÃ¡lise Inteligente**:
  - IdentificaÃ§Ã£o de padrÃµes de sucesso
  - ExtraÃ§Ã£o de fatores crÃ­ticos
  - RecomendaÃ§Ãµes baseadas em dados
  - Analytics avanÃ§ados

## ğŸ—ï¸ Arquitetura do Sistema

```
ğŸ“ Sistema de LicitaÃ§Ãµes dos Correios
â”œâ”€â”€ ğŸ–¥ï¸ Frontend (React)
â”‚   â”œâ”€â”€ ğŸ“Š AnÃ¡lise de LicitaÃ§Ãµes
â”‚   â”œâ”€â”€ ğŸ“ GeraÃ§Ã£o de Editais
â”‚   â””â”€â”€ ğŸ§  Base de Conhecimento
â”œâ”€â”€ ğŸ”§ Backend (FastAPI + Python)
â”‚   â”œâ”€â”€ ğŸ¤– Agentes CrewAI
â”‚   â”œâ”€â”€ ğŸ•·ï¸ Web Scraping (Playwright)
â”‚   â”œâ”€â”€ ğŸ—„ï¸ Banco de Dados (SQLite)
â”‚   â””â”€â”€ ğŸ”— APIs REST
â””â”€â”€ ğŸ“Š Dados
    â”œâ”€â”€ ğŸ“‹ Templates de Editais
    â”œâ”€â”€ ğŸ§  Base de Conhecimento
    â””â”€â”€ ğŸ“ˆ HistÃ³rico de LicitaÃ§Ãµes
```

## ğŸ› ï¸ Tecnologias Utilizadas

### Backend
- **FastAPI** - Framework web moderno e rÃ¡pido
- **CrewAI** - Framework para agentes de IA colaborativos
- **Playwright** - Web scraping moderno e confiÃ¡vel
- **SQLAlchemy** - ORM para banco de dados
- **OpenAI GPT** - Modelos de linguagem avanÃ§ados
- **SQLite** - Banco de dados leve e eficiente

### Frontend
- **React** - Biblioteca para interfaces de usuÃ¡rio
- **React Router** - Roteamento de pÃ¡ginas
- **CSS3** - EstilizaÃ§Ã£o moderna e responsiva

### Ferramentas de IA
- **CrewAI Agents** - Agentes especializados
- **OpenAI API** - Processamento de linguagem natural
- **AnÃ¡lise de PadrÃµes** - Machine learning para insights

## ğŸ“¦ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. PrÃ©-requisitos
```bash
# Python 3.8+
python --version

# Node.js 16+
node --version

# Git
git --version
```

### 2. ConfiguraÃ§Ã£o do Backend
```bash
# Clonar repositÃ³rio
git clone <repository-url>
cd licitacao-ai/backend

# Criar ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Instalar dependÃªncias
pip install -r requirements.txt

# Instalar Playwright
python -m playwright install chromium

# Configurar variÃ¡veis de ambiente
cp .env.example .env
# Editar .env com suas chaves de API
```

### 3. ConfiguraÃ§Ã£o do Frontend
```bash
cd ../frontend

# Instalar dependÃªncias
npm install

# Configurar variÃ¡veis de ambiente
cp .env.example .env.local
# Editar .env.local se necessÃ¡rio
```

### 4. InicializaÃ§Ã£o do Sistema
```bash
# Terminal 1 - Backend
cd backend
python -m uvicorn api.app:app --reload --port 8000

# Terminal 2 - Frontend
cd frontend
npm start

# Terminal 3 - Popular dados iniciais
cd backend
python utils/populate_initial_data.py

# Terminal 4 - Executar scraping inicial
cd backend
python scripts/run_scraping.py
```

## ğŸ¯ Como Usar

### 1. AnÃ¡lise de LicitaÃ§Ãµes
1. Acesse `http://localhost:3000`
2. Clique em "ğŸ“Š AnÃ¡lise"
3. Use a busca automÃ¡tica ou manual
4. Visualize resultados e anÃ¡lises

### 2. GeraÃ§Ã£o de Editais
1. Acesse `http://localhost:3000/gerar-edital`
2. Preencha dados bÃ¡sicos da licitaÃ§Ã£o
3. Configure requisitos avanÃ§ados
4. Aguarde processamento automÃ¡tico
5. Revise e baixe o edital gerado

### 3. Base de Conhecimento
1. Acesse `http://localhost:3000/base-conhecimento`
2. **Resumo**: Veja estatÃ­sticas gerais
3. **Consultar**: Busque licitaÃ§Ãµes similares
4. **Coletar Dados**: Execute web scraping
5. **Analytics**: Analise tendÃªncias

## ğŸ”§ APIs DisponÃ­veis

### AnÃ¡lise de LicitaÃ§Ãµes
- `GET /api/licitacoes` - Listar licitaÃ§Ãµes
- `POST /api/licitacoes/buscar` - Buscar novas licitaÃ§Ãµes
- `POST /api/licitacoes/analisar` - Analisar com IA

### GeraÃ§Ã£o de Editais
- `POST /api/editais/gerar` - Gerar novo edital
- `GET /api/editais/status/{id}` - Verificar status
- `GET /api/editais/{id}` - Obter edital gerado
- `GET /api/editais/templates` - Listar templates

### Base de Conhecimento
- `POST /api/scraping/executar` - Executar web scraping
- `GET /api/scraping/base-conhecimento/consultar` - Consultar base
- `GET /api/scraping/base-conhecimento/analytics` - Analytics
- `POST /api/scraping/agendar` - Agendar coleta automÃ¡tica

## ğŸ§  InteligÃªncia Artificial

### Agentes CrewAI
Cada agente tem especializaÃ§Ã£o especÃ­fica:

- **Coletor**: Valida e estrutura requisitos
- **JurÃ­dico**: Garante conformidade legal
- **TÃ©cnico**: Analisa viabilidade tÃ©cnica
- **Financeiro**: Valida aspectos econÃ´micos
- **Risco**: Calcula probabilidades de sucesso
- **Gerador**: Cria conteÃºdo do edital
- **Otimizador**: Aplica melhorias finais
- **Coordenador**: Gerencia processo completo
- **Conhecimento**: Aplica aprendizados da base

### Base de Conhecimento
- Coleta automÃ¡tica de licitaÃ§Ãµes bem-sucedidas
- AnÃ¡lise de padrÃµes de sucesso
- RecomendaÃ§Ãµes baseadas em dados histÃ³ricos
- Aprendizado contÃ­nuo do sistema

## ğŸ“Š Monitoramento e Logs

### Logs do Sistema
```bash
# Backend logs
tail -f backend/logs/app.log

# Scraping logs
tail -f backend/logs/scraping.log

# CrewAI logs
tail -f backend/logs/crewai.log
```

### MÃ©tricas Importantes
- Taxa de sucesso de editais gerados
- Tempo mÃ©dio de processamento
- Qualidade das anÃ¡lises de IA
- Cobertura da base de conhecimento

## ğŸ”’ SeguranÃ§a

- ValidaÃ§Ã£o de entrada em todas as APIs
- SanitizaÃ§Ã£o de dados de web scraping
- Rate limiting para APIs externas
- Logs de auditoria para aÃ§Ãµes crÃ­ticas

## ğŸš€ PrÃ³ximos Passos

### Melhorias Planejadas
1. **IntegraÃ§Ã£o com sistemas dos Correios**
2. **Dashboard executivo com KPIs**
3. **NotificaÃ§Ãµes automÃ¡ticas**
4. **API para integraÃ§Ã£o externa**
5. **Machine learning avanÃ§ado**
6. **AnÃ¡lise de sentimento em propostas**

### Escalabilidade
- MigraÃ§Ã£o para PostgreSQL
- Deploy em containers Docker
- ImplementaÃ§Ã£o de cache Redis
- Processamento assÃ­ncrono com Celery

## ğŸ“ Suporte

Para dÃºvidas ou problemas:
1. Verifique os logs do sistema
2. Consulte a documentaÃ§Ã£o da API
3. Execute testes de conectividade
4. Verifique configuraÃ§Ãµes de ambiente

## ğŸ“„ LicenÃ§a

Sistema desenvolvido para os Correios - Uso interno.

---

**ğŸ‰ Sistema completo e funcional para modernizar o processo de licitaÃ§Ãµes dos Correios com inteligÃªncia artificial!**
